{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_spec_c2CNN_w2-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RocioLiu/TensorFlow_Specialization/blob/master/tf_spec_c2CNN_w2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqZR9kKCzIT6",
        "colab_type": "text"
      },
      "source": [
        "## Cats v Dogs Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOAQEloeuOi2",
        "colab_type": "text"
      },
      "source": [
        "Let's start with a model that's very effective at learning Cats v Dogs.\n",
        "\n",
        "It's similar to the previous models that you have used, but I have updated the layers definition. Note that there are now 4 convolutional layers with 32, 64, 128 and 128 convolutions respectively.\n",
        "\n",
        "Also, this will train for 100 epochs, because I want to plot the graph of loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyiw7ggYuNOe",
        "colab_type": "code",
        "outputId": "2782b1a0-361b-4bac-901e-6460f035ec88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-12 01:25:10--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.112.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.112.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   102MB/s    in 0.6s    \n",
            "\n",
            "2019-07-12 01:25:11 (102 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNvixliyqh_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import shutil\n",
        "#shutil.rmtree('/tmp/cats_and_dogs_filtered') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TscT1M9puTmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTFnyH_su1zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlMG1WCqyO6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgcq16Bey9pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq2rzKpXz-aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(150,150,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1vpp0vvToWl",
        "colab_type": "code",
        "outputId": "88471df1-c5b3-4b7c-8a15-c39a0ffe49f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNT70YauTqz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6We6jazUUFHS",
        "colab_type": "code",
        "outputId": "79635c38-7dba-4047-df92-dc7dfdde2c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, # This is the source directory for training images\n",
        "    target_size = (150,150),\n",
        "    batch_size = 20,\n",
        "    # Since we use binary_crossentropy loss, we need binary labels\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "# Flow validation images in batches of 20 using vlidation_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir, # This is the source directory for vlidation images\n",
        "    target_size = (150,150),\n",
        "    batch_size = 20,\n",
        "    # Since we use binary_crossentropy loss, we need binary labels\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpIdpI0oVoeC",
        "colab_type": "code",
        "outputId": "61936168-aee8-4626-a070-042b9ca4588b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50,  # 1000 images = batch_size * steps\n",
        "    verbose = 1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.6910 - acc: 0.5280 - val_loss: 0.6744 - val_acc: 0.5810\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.6505 - acc: 0.6325 - val_loss: 0.6534 - val_acc: 0.6200\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.6083 - acc: 0.6745 - val_loss: 0.6474 - val_acc: 0.6180\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.5620 - acc: 0.7215 - val_loss: 0.5729 - val_acc: 0.6910\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.5319 - acc: 0.7335 - val_loss: 0.5507 - val_acc: 0.7200\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.4941 - acc: 0.7620 - val_loss: 0.5514 - val_acc: 0.7250\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.4622 - acc: 0.7780 - val_loss: 0.5276 - val_acc: 0.7260\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.4352 - acc: 0.7900 - val_loss: 0.5505 - val_acc: 0.7250\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.4146 - acc: 0.8100 - val_loss: 0.5581 - val_acc: 0.7410\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.3920 - acc: 0.8185 - val_loss: 0.5224 - val_acc: 0.7360\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.3525 - acc: 0.8470 - val_loss: 0.5420 - val_acc: 0.7350\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.3336 - acc: 0.8655 - val_loss: 0.5332 - val_acc: 0.7440\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.3122 - acc: 0.8625 - val_loss: 0.5583 - val_acc: 0.7500\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.2924 - acc: 0.8780 - val_loss: 0.5595 - val_acc: 0.7410\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.2706 - acc: 0.8905 - val_loss: 0.5872 - val_acc: 0.7360\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.2456 - acc: 0.9050 - val_loss: 0.6853 - val_acc: 0.7170\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.2267 - acc: 0.9125 - val_loss: 0.6241 - val_acc: 0.7400\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.1988 - acc: 0.9290 - val_loss: 0.6284 - val_acc: 0.7430\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.1775 - acc: 0.9350 - val_loss: 0.6405 - val_acc: 0.7530\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.1689 - acc: 0.9340 - val_loss: 0.6129 - val_acc: 0.7550\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.1406 - acc: 0.9530 - val_loss: 0.6445 - val_acc: 0.7510\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.1301 - acc: 0.9545 - val_loss: 0.7703 - val_acc: 0.7240\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.1153 - acc: 0.9585 - val_loss: 0.7068 - val_acc: 0.7570\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0920 - acc: 0.9730 - val_loss: 0.8048 - val_acc: 0.7300\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0749 - acc: 0.9780 - val_loss: 0.7781 - val_acc: 0.7510\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0694 - acc: 0.9815 - val_loss: 0.8163 - val_acc: 0.7360\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0625 - acc: 0.9865 - val_loss: 0.8336 - val_acc: 0.7410\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0530 - acc: 0.9855 - val_loss: 0.8938 - val_acc: 0.7510\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0427 - acc: 0.9880 - val_loss: 0.9241 - val_acc: 0.7470\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0430 - acc: 0.9870 - val_loss: 0.9040 - val_acc: 0.7450\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0346 - acc: 0.9930 - val_loss: 1.0110 - val_acc: 0.7420\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0297 - acc: 0.9915 - val_loss: 0.9883 - val_acc: 0.7450\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0292 - acc: 0.9915 - val_loss: 1.0695 - val_acc: 0.7300\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0261 - acc: 0.9940 - val_loss: 1.0940 - val_acc: 0.7460\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0172 - acc: 0.9975 - val_loss: 1.0756 - val_acc: 0.7560\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0206 - acc: 0.9960 - val_loss: 1.1740 - val_acc: 0.7470\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0173 - acc: 0.9945 - val_loss: 1.2050 - val_acc: 0.7470\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0211 - acc: 0.9930 - val_loss: 1.2514 - val_acc: 0.7420\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0101 - acc: 0.9980 - val_loss: 1.2211 - val_acc: 0.7510\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.0181 - acc: 0.9920 - val_loss: 1.2888 - val_acc: 0.7470\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0132 - acc: 0.9955 - val_loss: 1.3715 - val_acc: 0.7490\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0095 - acc: 0.9965 - val_loss: 1.4068 - val_acc: 0.7520\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0117 - acc: 0.9975 - val_loss: 1.3848 - val_acc: 0.7450\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0141 - acc: 0.9950 - val_loss: 1.3528 - val_acc: 0.7420\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0060 - acc: 0.9990 - val_loss: 1.4309 - val_acc: 0.7510\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0096 - acc: 0.9965 - val_loss: 1.4572 - val_acc: 0.7490\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.0129 - acc: 0.9955 - val_loss: 1.6129 - val_acc: 0.7420\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0062 - acc: 0.9990 - val_loss: 1.6047 - val_acc: 0.7390\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0122 - acc: 0.9965 - val_loss: 1.5918 - val_acc: 0.7410\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0109 - acc: 0.9960 - val_loss: 1.5455 - val_acc: 0.7360\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0048 - acc: 0.9980 - val_loss: 1.6109 - val_acc: 0.7360\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0041 - acc: 0.9990 - val_loss: 1.6601 - val_acc: 0.7430\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0021 - acc: 0.9995 - val_loss: 1.9826 - val_acc: 0.7420\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0209 - acc: 0.9925 - val_loss: 1.7600 - val_acc: 0.7360\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0067 - acc: 0.9975 - val_loss: 1.6637 - val_acc: 0.7350\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.7282 - val_acc: 0.7430\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0053 - acc: 0.9975 - val_loss: 1.8730 - val_acc: 0.7540\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0066 - acc: 0.9975 - val_loss: 1.8748 - val_acc: 0.7310\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0032 - acc: 0.9985 - val_loss: 1.8746 - val_acc: 0.7420\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0059 - acc: 0.9975 - val_loss: 1.7632 - val_acc: 0.7460\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.0161 - acc: 0.9960 - val_loss: 1.8919 - val_acc: 0.7450\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0020 - acc: 0.9995 - val_loss: 1.9086 - val_acc: 0.7480\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 2.1170e-04 - acc: 1.0000 - val_loss: 1.9479 - val_acc: 0.7480\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0130 - acc: 0.9960 - val_loss: 1.9796 - val_acc: 0.7350\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 7.0724e-04 - acc: 1.0000 - val_loss: 1.9378 - val_acc: 0.7440\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0052 - acc: 0.9970 - val_loss: 1.9096 - val_acc: 0.7550\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 7.4939e-04 - acc: 1.0000 - val_loss: 1.9797 - val_acc: 0.7550\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0059 - acc: 0.9975 - val_loss: 1.9816 - val_acc: 0.7430\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.0045 - acc: 0.9985 - val_loss: 1.9946 - val_acc: 0.7510\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0113 - acc: 0.9975 - val_loss: 2.0179 - val_acc: 0.7540\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.0010 - acc: 0.9995 - val_loss: 2.1315 - val_acc: 0.7520\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 1.6054e-04 - acc: 1.0000 - val_loss: 2.1542 - val_acc: 0.7570\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0072 - acc: 0.9980 - val_loss: 2.2734 - val_acc: 0.7340\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.0050 - acc: 0.9990 - val_loss: 2.1046 - val_acc: 0.7570\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.0038 - acc: 0.9985 - val_loss: 2.1717 - val_acc: 0.7420\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0043 - acc: 0.9990 - val_loss: 2.2298 - val_acc: 0.7470\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 7.8379e-04 - acc: 0.9995 - val_loss: 2.2170 - val_acc: 0.7390\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 110s 1s/step - loss: 0.0053 - acc: 0.9985 - val_loss: 2.1827 - val_acc: 0.7550\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0081 - acc: 0.9975 - val_loss: 2.2072 - val_acc: 0.7440\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 1.1228e-04 - acc: 1.0000 - val_loss: 2.2157 - val_acc: 0.7480\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0028 - acc: 0.9990 - val_loss: 2.3458 - val_acc: 0.7530\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0068 - acc: 0.9985 - val_loss: 2.4550 - val_acc: 0.7480\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0072 - acc: 0.9970 - val_loss: 2.4735 - val_acc: 0.7340\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0016 - acc: 0.9995 - val_loss: 2.4464 - val_acc: 0.7470\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0026 - acc: 0.9990 - val_loss: 2.3803 - val_acc: 0.7480\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0038 - acc: 0.9985 - val_loss: 2.3247 - val_acc: 0.7540\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 1.0253e-05 - acc: 1.0000 - val_loss: 2.5085 - val_acc: 0.7570\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0098 - acc: 0.9970 - val_loss: 2.8856 - val_acc: 0.7250\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0035 - acc: 0.9980 - val_loss: 2.3160 - val_acc: 0.7450\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0061 - acc: 0.9985 - val_loss: 2.5825 - val_acc: 0.7360\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0060 - acc: 0.9980 - val_loss: 2.3820 - val_acc: 0.7470\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 6.1966e-05 - acc: 1.0000 - val_loss: 2.4802 - val_acc: 0.7440\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0118 - acc: 0.9970 - val_loss: 2.3879 - val_acc: 0.7430\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 8.4298e-05 - acc: 1.0000 - val_loss: 2.5513 - val_acc: 0.7470\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0012 - acc: 0.9995 - val_loss: 2.4701 - val_acc: 0.7460\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0079 - acc: 0.9975 - val_loss: 2.6697 - val_acc: 0.7430\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 4.3102e-04 - acc: 1.0000 - val_loss: 2.6190 - val_acc: 0.7430\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.0042 - acc: 0.9980 - val_loss: 2.5320 - val_acc: 0.7440\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.0035 - acc: 0.9990 - val_loss: 2.7057 - val_acc: 0.7370\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 112s 1s/step - loss: 4.3162e-05 - acc: 1.0000 - val_loss: 2.5677 - val_acc: 0.7360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzmoNz1EZ96E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "23a2e655-f603-437b-9481-409d815c6f82"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation loss')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eWc5NzBPwtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation loss')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivw1yOGzkBIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIelUKvUUijg",
        "colab_type": "text"
      },
      "source": [
        "The Training Accuracy is close to 100%, and the validation accuracy is in the 70%-80% range. This is a great example of overfitting -- which in short means that it can do very well with images it has seen before, but not so well with images it hasn't. Let's see if we can do better to avoid overfitting -- and one simple method is to augment the images a bit. If you think about it, most pictures of a cat are very similar -- the ears are at the top, then the eyes, then the mouth etc. Things like the distance between the eyes and ears will always be quite similar too. \n",
        "\n",
        "What if we tweak with the images to change this up a bit -- rotate the image, squash it, etc.  That's what image augementation is all about. And there's an API that makes it easy...\n",
        "\n",
        "Now take a look at the ImageGenerator. There are properties on it that you can use to augment the image. \n",
        "\n",
        "```\n",
        "# Updated to do image augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "```\n",
        "These are just a few of the options available (for more, see the Keras documentation. Let's quickly go over what we just wrote:\n",
        "\n",
        "* rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures.\n",
        "* width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally.\n",
        "* shear_range is for randomly applying shearing transformations.\n",
        "* zoom_range is for randomly zooming inside pictures.\n",
        "* horizontal_flip is for randomly flipping half of the images horizontally. This is relevant when there are no assumptions of horizontal assymmetry (e.g. real-world pictures).\n",
        "* fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.\n",
        "\n",
        "\n",
        "Here's some code where we've added Image Augmentation. Run it to see the impact."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMwnjt1HUwv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQn2y1ymUw_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tnesorflow..keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZRY73uHUxBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ_X9F7rUxD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4peb59fZ1MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK9nUeZpZ1O0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKYEVHNiZ1be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXnIjI4XaI-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code has changed. Now instead of the ImageGenerator just rescaling\n",
        "# the image, we also rotate and do other operations\n",
        "# Updated to do image augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t6_wNVpcaD4",
        "colab_type": "code",
        "outputId": "aa014776-48ec-410f-8396-e142dd8bdf73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size=(150,150),\n",
        "      batch_size=20,\n",
        "      # Since we use binary_crossentropy loss, we need binary labels\n",
        "      class_mode='binary')\n",
        "\n",
        "# Flow training images in batches of 20 using validation_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size=(150,150),\n",
        "      batch_size=20,\n",
        "      # Since we use binary_crossentropy loss, we need binary labels\n",
        "      class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NLCQF__caGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,   # 2000 images = batch_size * steps\n",
        "      epochs=100,\n",
        "      validation_data = validation_dir,\n",
        "      validation_steps = 50, # 1000 images = batch_size * steps\n",
        "      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihhqHh2acaKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xvsRFnR3rWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMHLw1QY3rwZ",
        "colab_type": "text"
      },
      "source": [
        "Use **dropout** in the model to improve the performence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-dVZM963vso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HevGOGg35cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSporp\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aTmHoX34vsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGjaE2ua4oOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y__CrVA85evn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkTlO47_5eyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.5), # adding dropout layer here !!!!\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fHf6XQH4oRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=1e-4).\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVHm2TR26Dz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code has changed. Now instead of the ImageGenerator just rescaling\n",
        "# the image, we also rotate and do other operations\n",
        "# Updated to do image augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range = 40\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_model='nearest'\n",
        "      )\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkvSK_gD6D2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size=(150,150),\n",
        "      batch_size=20,\n",
        "      # Since we use binary_crossentropy loss, we need binary labels\n",
        "      class_mode='binary')\n",
        "\n",
        "# Flow training images in batches of 20 using validation_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size=(150,150),\n",
        "      batch_size=20,\n",
        "      # Since we use binary_crossentropy loss, we need binary labels\n",
        "      class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEgChYQN_cFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epochs=100,  # 2000 images = batch_size * steps\n",
        "      epochs=60,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyx6BeVR_9Ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training_accracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation_accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training_loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation_loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}