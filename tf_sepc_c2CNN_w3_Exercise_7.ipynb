{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_sepc_c2CNN_w3_Exercise 7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RocioLiu/TensorFlow_Specialization/blob/master/tf_sepc_c2CNN_w3_Exercise_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "b4175603-4e63-41d1-d583-84be9dc08729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150,150,3),\n",
        "                                include_top=False,\n",
        "                                weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-15 02:58:05--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.202.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   164MB/s    in 0.5s    \n",
            "\n",
            "2019-07-15 02:58:06 (164 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0715 02:58:07.231821 139892335159168 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "363cba27-2cd1-481c-edb5-501915c6e6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "2bdd37a7-e313-4c4e-afde-373a864d0199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0715 03:08:25.218162 139892335159168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "1098e690-e83d-49cf-e243-19a4b8673c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-15 03:10:26--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.214.128, 2607:f8b0:4001:c1b::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.214.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   171MB/s    in 0.8s    \n",
            "\n",
            "2019-07-15 03:10:27 (171 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-07-15 03:10:27--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.214.128, 2607:f8b0:4001:c17::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.214.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  69.3MB/s    in 0.2s    \n",
            "\n",
            "2019-07-15 03:10:28 (69.3 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "8571de97-ff0d-4376-9807-c99729c65680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses'\n",
        "train_humans_dir = '/tmp/training/humans'\n",
        "validation_horses_dir = '/tmp/validation/horses'\n",
        "validation_humans_dir = '/tmp/validation/humans'\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "6a600869-2565-4006-c851-2c6487d449c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1.0/255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size=(150,150),\n",
        "      batch_size=20,\n",
        "      class_mode='binary')     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size=(150,150),\n",
        "      batch_size=20,\n",
        "      class_mode='binary')\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "3ed191dc-34fe-4e75-8e7d-f95624cd9bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "      train_generator, \n",
        "      steps_per_epoch=52,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=13,\n",
        "      callbacks = [callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "52/52 [==============================] - 17s 325ms/step - loss: 0.2954 - acc: 0.8909 - val_loss: 0.0036 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 11s 206ms/step - loss: 0.1148 - acc: 0.9640 - val_loss: 0.0176 - val_acc: 0.9922\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0622 - acc: 0.9766 - val_loss: 0.0733 - val_acc: 0.9805\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0357 - acc: 0.9873 - val_loss: 0.0104 - val_acc: 0.9961\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0499 - acc: 0.9834 - val_loss: 0.0190 - val_acc: 0.9961\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0648 - acc: 0.9766 - val_loss: 0.0212 - val_acc: 0.9961\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 11s 210ms/step - loss: 0.0612 - acc: 0.9786 - val_loss: 0.0636 - val_acc: 0.9883\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0544 - acc: 0.9873 - val_loss: 0.0501 - val_acc: 0.9922\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0501 - acc: 0.9873 - val_loss: 0.0813 - val_acc: 0.9844\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 11s 213ms/step - loss: 0.0575 - acc: 0.9844 - val_loss: 0.1122 - val_acc: 0.9727\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 11s 213ms/step - loss: 0.0404 - acc: 0.9834 - val_loss: 0.0908 - val_acc: 0.9766\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0329 - acc: 0.9932 - val_loss: 0.0491 - val_acc: 0.9922\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0325 - acc: 0.9854 - val_loss: 0.0656 - val_acc: 0.9883\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0457 - acc: 0.9873 - val_loss: 0.0159 - val_acc: 0.9961\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0192 - acc: 0.9912 - val_loss: 1.3595e-05 - val_acc: 1.0000\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0412 - acc: 0.9893 - val_loss: 0.1264 - val_acc: 0.9766\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0329 - acc: 0.9912 - val_loss: 0.6938 - val_acc: 0.9492\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 11s 213ms/step - loss: 0.0246 - acc: 0.9903 - val_loss: 0.1256 - val_acc: 0.9844\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0254 - acc: 0.9922 - val_loss: 0.1742 - val_acc: 0.9805\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0371 - acc: 0.9903 - val_loss: 0.2762 - val_acc: 0.9648\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0175 - acc: 0.9942 - val_loss: 0.1491 - val_acc: 0.9805\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0607 - acc: 0.9932 - val_loss: 0.0772 - val_acc: 0.9844\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0211 - acc: 0.9942 - val_loss: 0.4940 - val_acc: 0.9570\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 11s 213ms/step - loss: 0.0260 - acc: 0.9912 - val_loss: 0.5337 - val_acc: 0.9570\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0068 - acc: 0.9961 - val_loss: 0.1508 - val_acc: 0.9805\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0163 - acc: 0.9942 - val_loss: 0.2747 - val_acc: 0.9688\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 11s 213ms/step - loss: 0.0224 - acc: 0.9922 - val_loss: 0.0992 - val_acc: 0.9844\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0116 - acc: 0.9971 - val_loss: 0.0654 - val_acc: 0.9922\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0132 - acc: 0.9942 - val_loss: 0.1694 - val_acc: 0.9766\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.1294 - val_acc: 0.9805\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0169 - acc: 0.9942 - val_loss: 0.2994 - val_acc: 0.9727\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0261 - acc: 0.9912 - val_loss: 0.1459 - val_acc: 0.9805\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 0.0185 - acc: 0.9951 - val_loss: 0.1483 - val_acc: 0.9766\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0133 - acc: 0.9961 - val_loss: 0.0582 - val_acc: 0.9922\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0163 - acc: 0.9942 - val_loss: 0.1155 - val_acc: 0.9805\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 11s 212ms/step - loss: 0.0155 - acc: 0.9951 - val_loss: 0.0902 - val_acc: 0.9883\n",
            "Epoch 37/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 6.6793e-04 - acc: 1.0000\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "52/52 [==============================] - 11s 211ms/step - loss: 6.5523e-04 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "c47ff202-18bc-47da-dfed-0b43eb3b1ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M6PhJQysd6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}